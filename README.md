# TranscriberApp

![Coverage](coverage.svg)


TranscriberApp es una herramienta modular diseÃ±ada para:

- **Transcribir audios mediante Whisper** con aceleraciÃ³n GPU en Jetson  
- **Procesar textos directamente** con anÃ¡lisis avanzado  
- **Generar resÃºmenes inteligentes** usando Gemini  
- **Extraer tareas de reuniones** (modo refinamiento)  
- **Crear resÃºmenes tÃ©cnicos, ejecutivos o en bullet points**  
- **Guardar resultados en formato Markdown**  
- **Ejecutar nativamente en Jetson con CUDA real**  
- **Interactuar con un asistente IA integrado**  
- **Consultar y ampliar informaciÃ³n mediante chat con streaming de tokens**  
- **Imprimir el resultado procesado en PDF**  
- **Interfaz moderna con overlay de carga y bloqueo de interacciÃ³n**  

![Imagen de muestra](https://raw.githubusercontent.com/FelixMarin/transcriberapp/refs/heads/main/screen.jpg)

---

## ğŸš€ CaracterÃ­sticas principales

- **TranscripciÃ³n automÃ¡tica** de archivos `.mp3` con Whisper acelerado por GPU  
- **Procesamiento directo** de archivos `.txt`  
- **Modos de anÃ¡lisis**: tÃ©cnico, refinamiento, ejecutivo, bullet, default  
- **Salida estructurada** en `outputs/`  
- **Transcripciones guardadas** en `transcripts/`  
- **Arquitectura modular y extensible**  
- **Compatibilidad total con NVIDIA Jetson**  
- **Wheels personalizados para PyTorch CUDA en JetPack 6.x**  
- **EjecuciÃ³n nativa optimizada para JetPack R36.x**  
- **Chat IA integrado con historial y contexto**  
- **Streaming de tokens para respuestas en tiempo real**  
- **Overlay de bloqueo con spinner durante el procesamiento**  
- **BotÃ³n de impresiÃ³n PDF en el panel de resultados**  
- **Control inteligente del botÃ³n "Procesar y enviar"**  
  - Solo se habilita cuando hay audio, nombre, email, modo y no existen resultados previos  

---

## ğŸ–¥ï¸ Compatibilidad

### **Entornos soportados:**
- âœ… **NVIDIA Jetson** (Orin Nano, Xavier, AGX Orin)  
- âœ… **JetPack 6.x (R36.x)**  
- âœ… **Python 3.10**  
- âœ… **CUDA 12.4 en el host**  

### âš ï¸ Nota importante sobre JetPack R36.4.7

TranscriberApp funciona perfectamente en ejecuciÃ³n nativa.  
No se recomienda el uso de contenedores en esta versiÃ³n de JetPack debido a incompatibilidades con CUDA.

---

## ğŸ“¦ Stack tecnolÃ³gico

### **Backend:**
- **Whisper** (OpenAI)  
- **PyTorch 2.3.0 + CUDA 12.4** (wheels personalizados para Jetson)  
- **FastAPI**  
- **Google Gemini API**  
- **ONNX Runtime GPU**  

### **Frontend:**
- HTML/CSS/JS  
- Chat IA con streaming  
- Overlay de carga  
- BotÃ³n de impresiÃ³n PDF  
- Renderizado Markdown con `marked.js`  

### **Infraestructura:**
- **EjecuciÃ³n nativa en Jetson**  
- **Entorno virtual Python 3.10**  

---

## ğŸ—ï¸ Arquitectura del proyecto

```
TranscriberApp/
â”‚
â”œâ”€â”€ audios/                     
â”œâ”€â”€ transcripts/                
â”œâ”€â”€ outputs/                    
â”œâ”€â”€ wheels/                     
â”‚   â”œâ”€â”€ torch_cuda_jetpack-2.3.0-py3-none-any.whl
â”‚   â”œâ”€â”€ torchaudio-2.3.0+952ea74-cp310-cp310-linux_aarch64.whl
â”‚   â”œâ”€â”€ torchvision-0.18.0a0+6043bc2-cp310-cp310-linux_aarch64.whl
â”‚   â”œâ”€â”€ openai_whisper-20250625-py3-none-any.whl
â”‚   â””â”€â”€ onnxruntime_gpu-1.19.0-cp310-cp310-linux_aarch64.whl
â”‚
â”œâ”€â”€ transcriber_app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ runner/
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ static/
â”‚       â”‚   â”œâ”€â”€ js/
â”‚       â”‚   â”‚   â”œâ”€â”€ recorder.js
â”‚       â”‚   â”‚   â”œâ”€â”€ chat.js
â”‚       â”‚   â”‚   â”œâ”€â”€ streaming.js
â”‚       â”‚   â”‚   â”œâ”€â”€ overlay.js
â”‚       â”‚   â”‚   â””â”€â”€ ui_validations.js
â”‚       â”‚   â”œâ”€â”€ css/
â”‚       â”‚   â””â”€â”€ img/
â”‚       â””â”€â”€ templates/
â”‚
â”œâ”€â”€ requirements_clean.txt      
â”œâ”€â”€ requirements.txt            
â”œâ”€â”€ .env                        
â””â”€â”€ README.md
```

---

## âš™ï¸ InstalaciÃ³n (EjecuciÃ³n nativa recomendada)

```bash
git clone <repositorio>
cd TranscriberApp

python3 -m venv venv_transcriber
source venv_transcriber/bin/activate

pip install -r requirements_clean.txt

pip install wheels/torch_cuda_jetpack-2.3.0-py3-none-any.whl
pip install wheels/torchaudio-2.3.0+952ea74-cp310-cp310-linux_aarch64.whl
pip install wheels/torchvision-0.18.0a0+6043bc2-cp310-cp310-linux_aarch64.whl
pip install wheels/openai_whisper-20250625-py3-none-any.whl
pip install wheels/onnxruntime_gpu-1.19.0-cp310-cp310-linux_aarch64.whl
```

Configurar API Key:

```bash
echo "GEMINI_API_KEY=TU_API_KEY" > .env
```

---

## ğŸ¯ Modos disponibles

| Modo | DescripciÃ³n |
|------|-------------|
| `default` | Resumen general |
| `tecnico` | Resumen tÃ©cnico |
| `refinamiento` | Tareas, backlog, decisiones |
| `ejecutivo` | Resumen corto para direcciÃ³n |
| `bullet` | Puntos clave |

---

## ğŸš€ EjecuciÃ³n

### CLI

```bash
python -m transcriber_app.main audio ejemplo tecnico
```

### Web API

```bash
uvicorn transcriber_app.web.web_app:app --host 0.0.0.0 --port 8000
```

Acceder a:

```
http://localhost:8000
```

---

## ğŸ“ Estructura de salida

```
transcripts/
outputs/
```

---

## ğŸ§  Funcionalidades avanzadas del frontend

### âœ” Chat IA integrado
- ConversaciÃ³n contextual basada en la transcripciÃ³n y el resumen  
- Historial persistente durante la sesiÃ³n  
- Respuestas en tiempo real mediante **streaming de tokens**  
- Formato enriquecido con saltos de lÃ­nea y listas  

### âœ” Overlay de carga
- Bloquea la interfaz durante el procesamiento  
- Spinner centrado  
- Evita interacciones errÃ³neas  

### âœ” BotÃ³n de impresiÃ³n PDF
- Disponible en el panel de **Resultado Procesado**  
- Imprime Ãºnicamente el contenido del resumen  
- Formato limpio y preparado para documentaciÃ³n  

### âœ” ValidaciÃ³n inteligente del botÃ³n "Procesar y enviar"
El botÃ³n solo se habilita cuando:

- Hay un audio grabado  
- Nombre, email y modo estÃ¡n completos  
- No existe transcripciÃ³n previa  
- No existe resultado procesado  

---

## ğŸ§  ConfiguraciÃ³n avanzada

Variables en `.env`:

```bash
GEMINI_API_KEY=...
SMTP_HOST=...
SMTP_PORT=465
SMTP_USER=...
SMTP_PASS=...
USE_MODEL=gemini-2.5-flash-lite
LANGUAGE=es
```

---

## ğŸŒ Acceso desde la red local (IMPORTANTE)

Para acceder a la interfaz web de **TranscriberApp** desde cualquier PC, mÃ³vil o tablet dentro de la misma red local, es necesario usar **HTTPS**, ya que los navegadores bloquean el acceso al micrÃ³fono (`getUserMedia()`) en conexiones HTTP que no sean `localhost`.

### âœ” Requisitos

1. **Caddy** instalado como reverse proxy HTTPS  
2. **Uvicorn** ejecutÃ¡ndose en el Jetson en `127.0.0.1:9000`  
3. **Caddy** escuchando en el puerto **443** y redirigiendo a Uvicorn  

### âœ” ConfiguraciÃ³n de Caddy

Archivo: `/etc/caddy/Caddyfile`

```
<IP_DEL_JETSON> {
    reverse_proxy 127.0.0.1:9000
}
```

Ejemplo:

```
192.168.0.105 {
    reverse_proxy 127.0.0.1:9000
}
```

Reiniciar Caddy:

```
sudo systemctl restart caddy
```

### âœ” Arranque de la aplicaciÃ³n

El servidor FastAPI debe ejecutarse **solo en local**, sin HTTPS:

```
uvicorn transcriber_app.web.web_app:app \
    --host 127.0.0.1 \
    --port 9000
```

### âœ” Acceso desde otros dispositivos

En cualquier navegador dentro de la red:

```
https://<IP_DEL_JETSON>
```

Ejemplo:

```
https://192.168.0.105
```

âš  **No usar `:9000`**, ya que ese puerto no sirve HTTPS.

### âœ” Â¿Por quÃ© es necesario?

Los navegadores solo permiten usar el micrÃ³fono si la pÃ¡gina se sirve desde:

- `https://â€¦`
- `http://localhost`
- `http://127.0.0.1`

Por eso, para acceder desde otro PC o mÃ³vil, es obligatorio usar **HTTPS**.

---

## ğŸ› SoluciÃ³n de problemas

### PyTorch sin CUDA
Instalar wheels personalizados.

### Whisper lento
Usar modelo mÃ¡s pequeÃ±o:

```bash
export MODEL_SIZE=tiny
```

### ONNX GPU no carga
Verificar:

```bash
python -c "import onnxruntime as ort; print(ort.get_device())"
```

---

## ğŸ“Œ Comandos Ãºtiles

### ğŸ§ Descargar audio desde YouTube

```bash
python transcriber_app/modules/audio_downloader.py "URL_DEL_VIDEO"
```

Ejemplo:

```bash
python transcriber_app/modules/audio_downloader.py "https://youtu.be/osKyvYJ3PRM?si=LM23Iu92g0oxG8ox"
```

### ğŸ§  Ejecutar el pipeline completo

```bash
python -m transcriber_app.main [audio|texto] [nombre] [modo]
```

Ejemplo:

```bash
python -m transcriber_app.main audio ejemplo1 tecnico
```

### ğŸŒ Ejecutar la API web

```bash
uvicorn transcriber_app.web.web_app:app --host 0.0.0.0 --port 8000
```

### â–¶ï¸ Ejecutar la app con el script de arranque

```bash
./start.sh
chmod +x start.sh
```

### ğŸ”¥ Matar procesos Python colgados

```bash
ps aux | grep python
kill -9 PID
```

### ğŸ§ª Ejecutar tests

```bash
pytest -q
```

### ğŸ§¹ Limpiar cachÃ©s de Python

```bash
find . -type d -name "__pycache__" -exec rm -r {} +
```

### ğŸ§© Verificar CUDA y PyTorch

```bash
python -c "import torch; print(torch.cuda.is_available())"
```

---

## ğŸ“Š Rendimiento en Jetson Orin Nano

| Componente | Tiempo | GPU |
|------------|--------|-----|
| Whisper base | 2â€“3 min | ~2GB |
| Gemini | 5â€“10 s | <1GB |

---

## ğŸ”„ Flujo tÃ­pico

1. Subir audio  
2. Transcribir  
3. Resumir  
4. Exportar  

---

## ğŸ“ˆ Roadmap

- ExportaciÃ³n a Jira  
- Dashboard web  
- DiarizaciÃ³n  
- ExportaciÃ³n avanzada a PDF  
- Modo conversaciÃ³n larga  

---

## ğŸ›¡ï¸ Seguridad

- API keys en `.env`  
- Datos locales  

---

## ğŸ“„ Licencia

MIT

---

## âœ¨ Agradecimientos

OpenAI, Google, NVIDIA, FastAPI, comunidad Jetson.
