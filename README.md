# TranscriberApp

TranscriberApp es una herramienta modular diseÃ±ada para:

- **Transcribir audios mediante Whisper** con aceleraciÃ³n GPU en Jetson  
- **Procesar textos directamente** con anÃ¡lisis avanzado  
- **Generar resÃºmenes inteligentes** usando Gemini  
- **Extraer tareas de reuniones** (modo refinamiento)  
- **Crear resÃºmenes tÃ©cnicos, ejecutivos o en bullet points**  
- **Guardar resultados en formato Markdown**  
- **Ejecutar nativamente en Jetson con CUDA real**  

---

## ğŸš€ CaracterÃ­sticas principales

- **TranscripciÃ³n automÃ¡tica** de archivos `.mp3` con Whisper acelerado por GPU  
- **Procesamiento directo** de archivos `.txt`  
- **Modos de anÃ¡lisis**: tÃ©cnico, refinamiento, ejecutivo, bullet, default  
- **Salida estructurada** en `outputs/`  
- **Transcripciones guardadas** en `transcripts/`  
- **Arquitectura modular y extensible**  
- **Compatibilidad total con NVIDIA Jetson**  
- **Wheels personalizados para PyTorch CUDA en JetPack 6.x**  
- **EjecuciÃ³n nativa optimizada para JetPack R36.x**  

---

## ğŸ–¥ï¸ Compatibilidad

### **Entornos soportados:**
- âœ… **NVIDIA Jetson** (Orin Nano, Xavier, AGX Orin)  
- âœ… **JetPack 6.x (R36.x)**  
- âœ… **Python 3.10**  
- âœ… **CUDA 12.4 en el host**  

### âš ï¸ Nota importante sobre JetPack R36.4.7

TranscriberApp funciona perfectamente en ejecuciÃ³n nativa.  
No se recomienda el uso de contenedores en esta versiÃ³n de JetPack debido a incompatibilidades con CUDA.

---

## ğŸ“¦ Stack tecnolÃ³gico

### **Backend:**
- **Whisper** (OpenAI)  
- **PyTorch 2.3.0 + CUDA 12.4** (wheels personalizados para Jetson)  
- **FastAPI**  
- **Google Gemini API**  
- **ONNX Runtime GPU**  

### **Infraestructura:**
- **EjecuciÃ³n nativa en Jetson**  
- **Entorno virtual Python 3.10**  

---

## ğŸ—ï¸ Arquitectura del proyecto

```
TranscriberApp/
â”‚
â”œâ”€â”€ audios/                     
â”œâ”€â”€ transcripts/                
â”œâ”€â”€ outputs/                    
â”œâ”€â”€ wheels/                     
â”‚   â”œâ”€â”€ torch_cuda_jetpack-2.3.0-py3-none-any.whl
â”‚   â”œâ”€â”€ torchaudio-2.3.0+952ea74-cp310-cp310-linux_aarch64.whl
â”‚   â”œâ”€â”€ torchvision-0.18.0a0+6043bc2-cp310-cp310-linux_aarch64.whl
â”‚   â”œâ”€â”€ openai_whisper-20250625-py3-none-any.whl
â”‚   â””â”€â”€ onnxruntime_gpu-1.19.0-cp310-cp310-linux_aarch64.whl
â”‚
â”œâ”€â”€ transcriber_app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ runner/
â”‚   â””â”€â”€ web/
â”‚
â”œâ”€â”€ requirements_clean.txt      
â”œâ”€â”€ requirements.txt            
â”œâ”€â”€ .env                        
â””â”€â”€ README.md
```

---

## âš™ï¸ InstalaciÃ³n (EjecuciÃ³n nativa recomendada)

```bash
git clone <repositorio>
cd TranscriberApp

python3 -m venv venv_transcriber
source venv_transcriber/bin/activate

pip install -r requirements_clean.txt

pip install wheels/torch_cuda_jetpack-2.3.0-py3-none-any.whl
pip install wheels/torchaudio-2.3.0+952ea74-cp310-cp310-linux_aarch64.whl
pip install wheels/torchvision-0.18.0a0+6043bc2-cp310-cp310-linux_aarch64.whl
pip install wheels/openai_whisper-20250625-py3-none-any.whl
pip install wheels/onnxruntime_gpu-1.19.0-cp310-cp310-linux_aarch64.whl
```

Configurar API Key:

```bash
echo "GEMINI_API_KEY=TU_API_KEY" > .env
```

---

## ğŸ¯ Modos disponibles

| Modo | DescripciÃ³n |
|------|-------------|
| `default` | Resumen general |
| `tecnico` | Resumen tÃ©cnico |
| `refinamiento` | Tareas, backlog, decisiones |
| `ejecutivo` | Resumen corto para direcciÃ³n |
| `bullet` | Puntos clave |

---

## ğŸš€ EjecuciÃ³n

### CLI

```bash
python -m transcriber_app.main audio ejemplo tecnico
```

### Web API

```bash
uvicorn transcriber_app.web.web_app:app --host 0.0.0.0 --port 8000
```

Acceder a:

```
http://localhost:8000
```

---

## ğŸ“ Estructura de salida

```
transcripts/
outputs/
```

---

## ğŸ§  ConfiguraciÃ³n avanzada

Variables en `.env`:

```bash
GEMINI_API_KEY=...
MODEL_SIZE=base
TARGET_LANG=es
LOG_LEVEL=INFO
```

# ğŸŒ Acceso desde la red local (IMPORTANTE)

Para acceder a la interfaz web de **TranscriberApp** desde cualquier PC, mÃ³vil o tablet dentro de la misma red local, es necesario usar **HTTPS**, ya que los navegadores bloquean el acceso al micrÃ³fono (`getUserMedia()`) en conexiones HTTP que no sean `localhost`.

## âœ” Requisitos

1. **Caddy** instalado como reverse proxy HTTPS  
2. **Uvicorn** ejecutÃ¡ndose en el Jetson en `127.0.0.1:9000`  
3. **Caddy** escuchando en el puerto **443** y redirigiendo a Uvicorn

## âœ” ConfiguraciÃ³n de Caddy

Archivo: `/etc/caddy/Caddyfile`

```
<IP_DEL_JETSON> {
    reverse_proxy 127.0.0.1:9000
}
```

Ejemplo:

```
192.168.0.105 {
    reverse_proxy 127.0.0.1:9000
}
```

Reiniciar Caddy:

```
sudo systemctl restart caddy
```

## âœ” Arranque de la aplicaciÃ³n

El servidor FastAPI debe ejecutarse **solo en local**, sin HTTPS:

```
uvicorn transcriber_app.web.web_app:app \
    --host 127.0.0.1 \
    --port 9000
```

## âœ” Acceso desde otros dispositivos

En cualquier navegador dentro de la red:

```
https://<IP_DEL_JETSON>
```

Ejemplo:

```
https://192.168.0.105
```

âš  **No usar `:9000`**, ya que ese puerto no sirve HTTPS.

## âœ” Â¿Por quÃ© es necesario?

Los navegadores solo permiten usar el micrÃ³fono si la pÃ¡gina se sirve desde:

- `https://â€¦`
- `http://localhost`
- `http://127.0.0.1`

Por eso, para acceder desde otro PC o mÃ³vil, es obligatorio usar **HTTPS**.

---

## ğŸ› SoluciÃ³n de problemas

### PyTorch sin CUDA

Instalar wheels personalizados.

### Whisper lento

Usar modelo mÃ¡s pequeÃ±o:

```bash
export MODEL_SIZE=tiny
```

### ONNX GPU no carga

Verificar:

```bash
python -c "import onnxruntime as ort; print(ort.get_device())"
```

# ğŸ“Œ Comandos Ãºtiles

Este apartado reÃºne los comandos mÃ¡s importantes para trabajar con TranscriberApp en modo nativo sobre Jetson.

---

## ğŸ§ Descargar audio desde YouTube

```bash
python transcriber_app/modules/audio_downloader.py "URL_DEL_VIDEO"
```

Ejemplo:

```bash
python transcriber_app/modules/audio_downloader.py "https://youtu.be/osKyvYJ3PRM?si=LM23Iu92g0oxG8ox"
```

El archivo descargado se guarda en `audios/`.

---

## ğŸ§  Ejecutar el pipeline completo

### Formato general

```bash
python -m transcriber_app.main [audio|texto] [nombre] [modo]
```

### Ejemplo (transcripciÃ³n + resumen tÃ©cnico)

```bash
python -m transcriber_app.main audio ejemplo1 tecnico
```

Esto genera:

- `transcripts/ejemplo1.txt`  
- `outputs/ejemplo1_tecnico.md`

---

## ğŸŒ Ejecutar la API web

```bash
uvicorn transcriber_app.web.web_app:app --host 0.0.0.0 --port 8000
```

Acceso:

```
http://localhost:8000
```

---

## â–¶ï¸ Ejecutar la app con el script de arranque

```bash
./start.sh
```

AsegÃºrate de haber dado permisos:

```bash
chmod +x start.sh
```

---

## ğŸ”¥ Matar procesos Python que se quedan colgados

Listar procesos:

```bash
ps aux | grep python
```

Matar uno:

```bash
kill -9 PID
```

---

## ğŸ§ª Ejecutar tests

```bash
pytest -q
```

---

## ğŸ§¹ Limpiar cachÃ©s de Python

```bash
find . -type d -name "__pycache__" -exec rm -r {} +
```

---

## ğŸ§© Verificar CUDA y PyTorch en el host

```bash
python -c "import torch; print(torch.cuda.is_available())"
```

---

## ğŸ“Š Rendimiento en Jetson Orin Nano

| Componente | Tiempo | GPU |
|------------|--------|-----|
| Whisper base | 2â€“3 min | ~2GB |
| Gemini | 5â€“10 s | <1GB |

---

## ğŸ”„ Flujo tÃ­pico

1. Subir audio  
2. Transcribir  
3. Resumir  
4. Exportar  

---

## ğŸ“ˆ Roadmap

- ExportaciÃ³n a Jira  
- Dashboard web  
- Streaming  
- DiarizaciÃ³n  

---

## ğŸ›¡ï¸ Seguridad

- API keys en `.env`  
- Datos locales  

---

## ğŸ“„ Licencia

MIT

---

## âœ¨ Agradecimientos

OpenAI, Google, NVIDIA, FastAPI, comunidad Jetson.
